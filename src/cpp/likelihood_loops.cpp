/*~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\
|  Phycas: Python software for phylogenetic analysis                          |
|  Copyright (C) 2006 Mark T. Holder, Paul O. Lewis and David L. Swofford     |
|                                                                             |
|  This program is free software; you can redistribute it and/or modify       |
|  it under the terms of the GNU General Public License as published by       |
|  the Free Software Foundation; either version 2 of the License, or          |
|  (at your option) any later version.                                        |
|                                                                             |
|  This program is distributed in the hope that it will be useful,            |
|  but WITHOUT ANY WARRANTY; without even the implied warranty of             |
|  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the              |
|  GNU General Public License for more details.                               |
|                                                                             |
|  You should have received a copy of the GNU General Public License along    |
|  with this program; if not, write to the Free Software Foundation, Inc.,    |
|  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.                |
\~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*/

#define DO_UNDERFLOW_POLICY
//#undef DO_UNDERFLOW_POLICY

//#if defined(_MSC_VER)
//#	pragma warning(error : 4710) // reports functions not inlined as errors
//#endif

#include "ncl/nxsutilcopy.h"

#include "basic_tree.hpp"
#include "cond_likelihood.hpp"
#include "model.hpp"
#include "tree_likelihood.hpp"
#include "tip_data.hpp"
#include "internal_data.hpp"
#include "edge_endpoints.hpp"
#include <numeric>

//for XCode debugging:
//#include <CoreServices/CoreServices.h>
//#undef check	// defined somewhere due to above include

#include <iostream>
using std::cerr;
using std::endl;

#include <cmath>
using std::log;

using std::accumulate;

template<typename T>
void transpose(T * * mat, unsigned dim);

using std::vector;

template<typename T>
void transpose(T * * mat, unsigned dim)
	{
	for (unsigned i = 0; i < dim; ++i)
		for (unsigned j = i + 1; j < dim; ++j)
			std::swap(mat[i][j], mat[j][i]);
	}

#define AA  0
#define AC  1
#define AG  2
#define AT  3
#define CA  4
#define CC  5
#define CG  6
#define CT  7
#define GA  8
#define GC  9
#define GG  10
#define GT  11
#define TA  12
#define TC  13
#define TG  14
#define TT  15

namespace phycas
{

/*----------------------------------------------------------------------------------------------------------------------
|	Calculates a transition matrix for every rate category given the supplied `edgeLength' and the subset indexed by `i'.
|	This function calculates the basic square transition matrix in which rows represent "from" states and columns
|	represent "to" states. For tips, the transition matrix generated by this function is transposed by both
|	TreeLikelihood::calcPMatTranspose and TreeLikelihood::calcTMatForSim, and in the case of
|	TreeLikelihood::calcPMatTranspose also augmented by adding rows corresponding to the observed tip-specific
|	ambiguities.
*/
void TreeLikelihood::calcPMatCommon(
  unsigned		i,				/**< is the subset of the partition */
  double * * *	pMatrices, 		/**< is a pointer to the transition matrix to be calculated */
  double		edgeLength)		/**< is the edge length */
	{
	unsigned nr = partition_model->subset_num_rates[i];
	double subset_relrate = partition_model->getSubsetRelRate(i);
	PHYCAS_ASSERT(nr > 0);
	vector<double> scaled_edges(nr);
	for (unsigned r = 0; r < nr; ++r)
		{
        double ratemean = rate_means[i][r];
		scaled_edges[r] = subset_relrate*edgeLength*ratemean;
		}
    //std::cerr << boost::str(boost::format("calcPMatCommon: i = %d, subset rate = %g, edgelen = %g, scaled_edges = %g") % i % subset_relrate % edgeLength % scaled_edges[0]) << std::endl;
	partition_model->subset_model[i]->calcPMatrices(pMatrices, &scaled_edges[0], nr); //PELIGROSO
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Calls calcPMatCommon to compute the transition matrix for an internal node given the value of `edgeLength'.
*/
void TreeLikelihood::calcPMat(
  unsigned		i,				/**< is the subset of the partition */
  double * * *	p, 				/**< is a pointer to the transition matrix to be calculated */
  double		edgeLength)		/**< is the edge length */
	{
	calcPMatCommon(i, p, edgeLength);
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Calculates tip-specific transition matrices for purposes of simulation. These are transposed but not augmented
|	transition matrices. They are not augmented because no ambiguities are generated when simulating data and thus no
|	additional rows are necessary.
*/
void TreeLikelihood::calcTMatForSim(
  unsigned i,               /**< is the subset of the partition */
  TipData &	tipData,        /**< is the structure holding the transition matrices to fill */
  double	edgeLength)     /**< is the edge length to use in scaling transition probabilities */
	{
    // formerly DISABLED_UNTIL_SIMULATION_WORKING_WITH_PARTITIONING
	double * * * transPMats = tipData.getTransposedPMatrices(i);    //POLSIM
	calcPMatCommon(i, transPMats,  edgeLength);    //POLSIM

    unsigned nr = partition_model->subset_num_rates[i]; //POLSIM
    unsigned ns = partition_model->subset_num_states[i]; //POLSIM

	// For each rate category, transpose the num_states x num_states portion of the matrices
	for (unsigned rate = 0; rate < nr; ++rate)
		{
		double * * pMat = transPMats[rate];
		transpose(pMat, ns);
		}
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Calculates tip-specific transition matrices for purposes of computing likelihoods. The resulting matrices are
|	T matrices: transposed and augmented transition matrices.
*/
void TreeLikelihood::calcPMatTranspose(
  unsigned				i,					/**< is the subset of the partition */
  double * * * 			transPMats,			/**< is the transition matrix to be calculated */
  const StateListPos &	stateListPosVec, 	/**< holds the locations of each state in the state list */
  double				edgeLength)			/**< is the edge length */
	{
	unsigned nr = partition_model->subset_num_rates[i];
	unsigned ns = partition_model->subset_num_states[i];
	calcPMatCommon(i, transPMats, edgeLength);

	// For each rate category, transpose the ns X ns portion of the matrices
	// and fill in the ambiguity codes by summing columns
	const unsigned				nPartialAmbigs	= (unsigned)stateListPosVec.size();
	const state_list_t			stateListVec 	= state_list[i];
	const int8_t * const 		stateListArr = &stateListVec[0]; //PELIGROSO
	for (unsigned rate = 0; rate < nr; ++rate)
		{
		// Transpose the matrix
		double * * pMat = transPMats[rate];
		transpose(pMat, ns);

		// Add a row corresponding to complete ambiguity, setting every element in this row to 1.0
		unsigned currPMatRowIndex = ns;
		std::fill(pMat[currPMatRowIndex], pMat[currPMatRowIndex] + ns, 1.0);
		++currPMatRowIndex;

		// Add a row for every additional type of ambiguity seen
		for (unsigned ambigCode = 0; ambigCode < nPartialAmbigs; ++ambigCode, ++currPMatRowIndex)
			{
			const unsigned int * const 	stateListPosArr 	= &stateListPosVec[0]; //PELIGROSO //POL-31Dec2008
			unsigned 					indexIntoStateList 	= stateListPosArr[ambigCode];
			const unsigned 				nObservedStates 	= stateListArr[indexIntoStateList++];
			unsigned 					currObservedState 	= stateListArr[indexIntoStateList++];
			ncl_copy(pMat[currObservedState], pMat[currObservedState] + ns, pMat[currPMatRowIndex]);
			for (unsigned m = 1; m < nObservedStates; ++m)
				{
				currObservedState = stateListArr[indexIntoStateList++];
				ncl_iadd(pMat[currObservedState], pMat[currObservedState] + ns, pMat[currPMatRowIndex]);
				}
			}
		}
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Computes the conditional likelihood arrays at an internal node subtending two tips.
*/
void TreeLikelihood::calcCLATwoTips(
  CondLikelihood & 		condLike,
  const TipData &		leftTip,
  const TipData &		rightTip)
	{
    // cla is the conditional likelihood array we are updating
    LikeFltType * cla = condLike.getCLA();

    unsigned num_subsets = partition_model->getNumSubsets();
    for (unsigned i = 0; i < num_subsets; ++i)
        {
        const double * const * const * leftPMatricesTrans = leftTip.getConstTransposedPMatrices(i);
        const int8_t * leftStateCodes = leftTip.getConstStateCodes(i);
        const double * const * const * rightPMatricesTrans = rightTip.getConstTransposedPMatrices(i);
        const int8_t * rightStateCodes = rightTip.getConstStateCodes(i);
        unsigned num_patterns = partition_model->subset_num_patterns[i];
        unsigned num_states = partition_model->subset_num_states[i];
        unsigned num_rates = partition_model->subset_num_rates[i];
        for (unsigned r = 0; r < num_rates; ++r)
            {
            const double * const * leftPMatT = leftPMatricesTrans[r];
            const double * const * const rightPMatT = rightPMatricesTrans[r];
            for (unsigned p = 0; p < num_patterns; ++p, cla += num_states)
                {
                const double * leftPMatTRow = leftPMatT[leftStateCodes[p]];
                const double * rightPMatTRow = rightPMatT[rightStateCodes[p]];
                for (unsigned s = 0; s < num_states; ++s)
                    {
                    double leftprob = leftPMatTRow[s];
                    double rightprob = rightPMatTRow[s];
                    cla[s] = leftprob*rightprob;

                    //@POLTEMP
                    //std::cerr << boost::str(boost::format("subset=%d, rate=%d, pattern=%d, state=%d, left=%g, right=%g, cla=%g") % i % r % p % s % leftprob % rightprob % cla[s]) << std::endl;
                    }
                }
            }
        }
#if defined(DO_UNDERFLOW_POLICY)
	underflow_manager.twoTips(condLike);
#endif
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Computes the conditional likelihood arrays at an internal node having a tip node as its left child and an internal
|	node for a right child.
*/
void TreeLikelihood::calcCLAOneTip(
  CondLikelihood &			condLike,
  const TipData &			leftChild,
  const InternalData &		rightChild,
  const CondLikelihood &	rightCondLike)
	{
    // cla is the conditional likelihood array we are updating
    LikeFltType * cla = condLike.getCLA();

    // rightCLA is the conditional likelihood array of the internal child node
    const double * rightCLA = rightCondLike.getCLA();

    unsigned num_subsets = partition_model->getNumSubsets();
    for (unsigned i = 0; i < num_subsets; ++i)
        {
        unsigned num_patterns = partition_model->subset_num_patterns[i];
        unsigned num_states = partition_model->subset_num_states[i];
        unsigned num_rates = partition_model->subset_num_rates[i];

        // Get transition probability matrices for the left and right child nodes of this node
        // These are 3D because there are potentially several 2D transition matrices, one
        // for each relative rate
        ConstPMatrices leftPMatricesTrans = leftChild.getConstTransposedPMatrices(i);
        ConstPMatrices rightPMatrices = rightChild.getConstPMatrices(i);

        // Get the state codes for the tip child
        const int8_t * leftStateCodes = leftChild.getConstStateCodes(i);

        // conditional likelihood arrays are laid out as follows for DNA data:
        //
        // +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
        // |   pattern 1   |               |               |               |               |
        // +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
        // | A | C | G | T | A | C | G | T | A | C | G | T | A | C | G | T | A | C | G | T |
        // +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
        //
        for (unsigned r = 0; r < num_rates; ++r)
            {
            const double * const * const leftPMatrixT = leftPMatricesTrans[r];
            const double * const * rightPMatrix = rightPMatrices[r];
            if (num_states == 4)
                {
                //POL 16-June-2006 Unrolling the nested loops across states here as well as in TreeLikelihood::calcCLANoTips
                // resulted in a 26.6% speedup on Windows using green.nex and SVN version 97
                for (unsigned pat = 0; pat < num_patterns; ++pat)
                    {
                    const double * leftPMatT_pat = leftPMatrixT[leftStateCodes[pat]];
                    double rightCLA0 = *rightCLA++;
                    double rightCLA1 = *rightCLA++;
                    double rightCLA2 = *rightCLA++;
                    double rightCLA3 = *rightCLA++;

                    // *** from state 0
                    const double * rightP_i = rightPMatrix[0];
                    double right0 = (*rightP_i++)*rightCLA0;
                    double right1 = (*rightP_i++)*rightCLA1;
                    double right2 = (*rightP_i++)*rightCLA2;
                    double right3 = (*rightP_i++)*rightCLA3;
                    double right_side = right0 + right1 + right2 + right3;
                    *cla++ = ((*leftPMatT_pat++)*right_side);

                    // *** from state 1
                    rightP_i = rightPMatrix[1];
                    right0 = (*rightP_i++)*rightCLA0;
                    right1 = (*rightP_i++)*rightCLA1;
                    right2 = (*rightP_i++)*rightCLA2;
                    right3 = (*rightP_i++)*rightCLA3;
                    right_side = right0 + right1 + right2 + right3;
                    *cla++ = ((*leftPMatT_pat++)*right_side);

                    // *** from state 2
                    rightP_i = rightPMatrix[2];
                    right0 = (*rightP_i++)*rightCLA0;
                    right1 = (*rightP_i++)*rightCLA1;
                    right2 = (*rightP_i++)*rightCLA2;
                    right3 = (*rightP_i++)*rightCLA3;
                    right_side = right0 + right1 + right2 + right3;
                    *cla++ = ((*leftPMatT_pat++)*right_side);

                    // *** from state 3
                    rightP_i = rightPMatrix[3];
                    right0 = (*rightP_i++)*rightCLA0;
                    right1 = (*rightP_i++)*rightCLA1;
                    right2 = (*rightP_i++)*rightCLA2;
                    right3 = (*rightP_i++)*rightCLA3;
                    right_side = right0 + right1 + right2 + right3;
                    *cla++ = ((*leftPMatT_pat++)*right_side);
                    }
                }
            else	// num_states not 4
                {
                for (unsigned pat = 0; pat < num_patterns; ++pat, rightCLA += num_states)
                    {
                    const double * leftPMatT_pat = leftPMatrixT[leftStateCodes[pat]];
                    for (unsigned i = 0; i < num_states; ++i)
                        {
                        double right_side = 0.0;
                        const double * rightP_i = rightPMatrix[i];
                        for (unsigned j = 0; j < num_states; ++j)
                            right_side += rightP_i[j]*rightCLA[j];
                        *cla++ = (leftPMatT_pat[i]*right_side);
                        }
                    }
                }
            } // loop over rates
        } // loop over subsets of partition

#if defined(DO_UNDERFLOW_POLICY)
	underflow_manager.check(condLike, rightCondLike, rightCondLike, pattern_counts, false);	// last argument is polytomy
#endif
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Computes the conditional likelihood arrays at an internal node having two internal nodes for children.
*/
void TreeLikelihood::calcCLANoTips(
  CondLikelihood &			condLike,
  const InternalData &		leftChild,
  const CondLikelihood &	leftCondLike,
  const InternalData &		rightChild,
  const CondLikelihood &	rightCondLike)
	{
    // cla is the conditional likelihood array we are updating
    LikeFltType * cla = condLike.getCLA();

    // These are the conditional likelihood arrays of the left and right child nodes of this node
    const LikeFltType * leftCLA  = leftCondLike.getCLA();
    const LikeFltType * rightCLA = rightCondLike.getCLA();

    unsigned num_subsets = partition_model->getNumSubsets();
    for (unsigned i = 0; i < num_subsets; ++i)
        {
        unsigned num_patterns = partition_model->subset_num_patterns[i];
        unsigned num_states = partition_model->subset_num_states[i];
        unsigned num_rates = partition_model->subset_num_rates[i];

        ConstPMatrices leftPMatrices = leftChild.getConstPMatrices(i);
        ConstPMatrices rightPMatrices = rightChild.getConstPMatrices(i);

        // This function updates the conditional likelihood array of a node assuming that the
        // conditional likelihood arrays of its left and right children have already been
        // updated

        // conditional likelihood arrays are laid out as follows for DNA data:
        //
        // +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
        // |                            rate 1                             | ...
        // +---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        // |   pattern 1   |   pattern 2   |      ...      |   pattern n   | ...
        // +---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        // | A | C | G | T | A | C | G | T |      ...      | A | C | G | T | ...
        // +---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        //
        for (unsigned r = 0; r < num_rates; ++r)
            {
            double const * const * leftPMatrix  = leftPMatrices[r];
            double const * const * rightPMatrix = rightPMatrices[r];
            if (num_states == 4)
                {
                //POL 16-June-2006 Unrolling the nested loops across states here as well as in TreeLikelihood::calcCLAOneTip
                // resulted in a 26.6% speedup on Windows using green.nex and SVN version 97
                for (unsigned pat = 0; pat < num_patterns; ++pat)
                    {
                    double leftCLA0 = *leftCLA++;
                    double leftCLA1 = *leftCLA++;
                    double leftCLA2 = *leftCLA++;
                    double leftCLA3 = *leftCLA++;
                    double rightCLA0 = *rightCLA++;
                    double rightCLA1 = *rightCLA++;
                    double rightCLA2 = *rightCLA++;
                    double rightCLA3 = *rightCLA++;

                    // *** from state 0 ***
                    const double * leftP_i  = leftPMatrix[0];
                    const double * rightP_i = rightPMatrix[0];

                    // to state 0
                    double left0 = (*leftP_i++)*leftCLA0;
                    double right0 = (*rightP_i++)*rightCLA0;

                    // to state 1
                    double left1 = (*leftP_i++)*leftCLA1;
                    double right1 = (*rightP_i++)*rightCLA1;

                    // to state 2
                    double left2 = (*leftP_i++)*leftCLA2;
                    double right2 = (*rightP_i++)*rightCLA2;

                    // to state 3
                    double left3 = (*leftP_i++)*leftCLA3;
                    double right3 = (*rightP_i++)*rightCLA3;

                    double left_side  = left0 + left1 + left2 + left3;
                    double right_side = right0 + right1 + right2 + right3;
                    *cla++ = (left_side*right_side);

                    // *** from state 1 ***
                    leftP_i  = leftPMatrix[1];
                    rightP_i = rightPMatrix[1];

                    // to state 0
                    left0 = (*leftP_i++)*leftCLA0;
                    right0 = (*rightP_i++)*rightCLA0;

                    // to state 1
                    left1 = (*leftP_i++)*leftCLA1;
                    right1 = (*rightP_i++)*rightCLA1;

                    // to state 2
                    left2 = (*leftP_i++)*leftCLA2;
                    right2 = (*rightP_i++)*rightCLA2;

                    // to state 3
                    left3 = (*leftP_i++)*leftCLA3;
                    right3 = (*rightP_i++)*rightCLA3;

                    left_side  = left0 + left1 + left2 + left3;
                    right_side = right0 + right1 + right2 + right3;
                    *cla++ = (left_side*right_side);

                    // *** from state 2 ***
                    leftP_i  = leftPMatrix[2];
                    rightP_i = rightPMatrix[2];

                    // to state 0
                    left0 = (*leftP_i++)*leftCLA0;
                    right0 = (*rightP_i++)*rightCLA0;

                    // to state 1
                    left1 = (*leftP_i++)*leftCLA1;
                    right1 = (*rightP_i++)*rightCLA1;

                    // to state 2
                    left2 = (*leftP_i++)*leftCLA2;
                    right2 = (*rightP_i++)*rightCLA2;

                    // to state 3
                    left3 = (*leftP_i++)*leftCLA3;
                    right3 = (*rightP_i++)*rightCLA3;

                    left_side  = left0 + left1 + left2 + left3;
                    right_side = right0 + right1 + right2 + right3;
                    *cla++ = (left_side*right_side);

                    // *** from state 3 ***
                    leftP_i  = leftPMatrix[3];
                    rightP_i = rightPMatrix[3];

                    // to state 0
                    left0 = (*leftP_i++)*leftCLA0;
                    right0 = (*rightP_i++)*rightCLA0;

                    // to state 1
                    left1 = (*leftP_i++)*leftCLA1;
                    right1 = (*rightP_i++)*rightCLA1;

                    // to state 2
                    left2 = (*leftP_i++)*leftCLA2;
                    right2 = (*rightP_i++)*rightCLA2;

                    // to state 3
                    left3 = (*leftP_i++)*leftCLA3;
                    right3 = (*rightP_i++)*rightCLA3;

                    left_side  = left0 + left1 + left2 + left3;
                    right_side = right0 + right1 + right2 + right3;
                    *cla++ = (left_side*right_side);
                    }
                }
            else	// num_states != 4
                {
                for (unsigned pat = 0; pat < num_patterns; ++pat, leftCLA += num_states, rightCLA += num_states)
                    {
                    for (unsigned i = 0; i < num_states; ++i)
                        {
                        double left_side  = 0.0;
                        double right_side = 0.0;
                        const double * leftP_i  = leftPMatrix[i];
                        const double * rightP_i = rightPMatrix[i];
                        for (unsigned j = 0; j < num_states; ++j)
                            {
                            left_side  += (leftP_i[j]*leftCLA[j]);
                            right_side += (rightP_i[j]*rightCLA[j]);
                            }
                        *cla++ = (left_side*right_side);
                        }
                    }
                }
            }	// loop over rates
        } // loop across subsets of partition

#if defined(DO_UNDERFLOW_POLICY)
	underflow_manager.check(condLike, leftCondLike, rightCondLike, pattern_counts, false);	// last argument is polytomy
#endif
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Modifies the conditional likelihood arrays for an internal node having more than two children. This function
|	handles situations in which an additional child (beyond the first two) is a tip. The conditional likelihood arrays
|	should already have been calculated for the first two children using TreeLikelihood::calcCLATwoTips,
|	TreeLikelihood::calcCLAOneTip or TreeLikelihood::calcCLANoTips.
*/
void TreeLikelihood::conditionOnAdditionalTip(
  CondLikelihood &	condLike,
  const TipData &	tipData)
	{
	LikeFltType * cla = condLike.getCLA();

    unsigned num_subsets = partition_model->getNumSubsets();
    for (unsigned i = 0; i < num_subsets; ++i)
        {
        unsigned num_patterns = partition_model->subset_num_patterns[i];
        unsigned num_states = partition_model->subset_num_states[i];
        unsigned num_rates = partition_model->subset_num_rates[i];

        const double * const * const * tipPMatricesTrans = tipData.getConstTransposedPMatrices(i);
        const int8_t * tipStateCodes = tipData.getConstStateCodes(i);

        //	+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
        //	|                            rate 1                             | ...
        //	+---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        //	|   pattern 1   |   pattern 2   |      ...      |   pattern n   | ...
        //	+---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        //	| A | C | G | T | A | C | G | T |      ...      | A | C | G | T | ...
        //	+---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        for (unsigned r = 0; r < num_rates; ++r)
            {
            const double * const * const tipPMatrixT = tipPMatricesTrans[r];
            for (unsigned pat = 0; pat < num_patterns; ++pat)
                {
                const double * tipPMatT_pat = tipPMatrixT[tipStateCodes[pat]];
                for (unsigned i = 0; i < num_states; ++i)
                    *cla++ *= tipPMatT_pat[i];
                }   // loop across patterns
            }   // loop across rates
        } // loop across subsets of partition

#if defined(DO_UNDERFLOW_POLICY)
	//std::cerr << "@@@@@@@@@@@@@@ additional tip @@@@@@@@@@@@@@" << std::endl;
	// Note: check() has 3 CondLikelihood & args, but we only need 1 of them, so provide condLike 3 times
	underflow_manager.check(condLike, condLike, condLike, pattern_counts, true);	// last argument is polytomy
#endif
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Modifies the conditional likelihood arrays for an internal node having more than two children. This function
|	handles situations in which an additional child (beyond the first two) is an internal node. The conditional
|	likelihood arrays should already have been calculated for the first two children using
|	TreeLikelihood::calcCLATwoTips, TreeLikelihood::calcCLAOneTip or TreeLikelihood::calcCLANoTips.
*/
void TreeLikelihood::conditionOnAdditionalInternal(
  CondLikelihood &			condLike,
  const InternalData &		child,
  const CondLikelihood &	childCondLike)
	{
	double * cla = condLike.getCLA();
	const double * childCLA = childCondLike.getCLA();

    unsigned num_subsets = partition_model->getNumSubsets();
    for (unsigned i = 0; i < num_subsets; ++i)
        {
        unsigned num_patterns = partition_model->subset_num_patterns[i];
        unsigned num_states = partition_model->subset_num_states[i];
        unsigned num_rates = partition_model->subset_num_rates[i];

        ConstPMatrices childPMatrices = child.getConstPMatrices(i);

        //	+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
        //	|                            rate 1                             | ...
        //	+---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        //	|   pattern 1   |   pattern 2   |      ...      |   pattern n   | ...
        //	+---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        //	| A | C | G | T | A | C | G | T |      ...      | A | C | G | T | ...
        //	+---+---+---+---+---+---+---+---+---------------+---+---+---+---+
        for (unsigned r = 0; r < num_rates; ++r)
            {
            const double * const * childPMatrix = childPMatrices[r];
            for (unsigned pat = 0; pat < num_patterns; ++pat, childCLA += num_states)
                {
                for (unsigned i = 0; i < num_states; ++i)
                    {
                    double childLike = 0.0;
                    const double * childP_i = childPMatrix[i];
                    for (unsigned j = 0; j < num_states; ++j)
                        childLike += childP_i[j]*childCLA[j];
                    *cla++ *= childLike;
                    }   // loop across states
                }   // loop across patterns
		    } // loop across rates
		} // loop across subsets of partition

#if defined(DO_UNDERFLOW_POLICY)
	//std::cerr << "@@@@@@@@@@@@@@ additional tip @@@@@@@@@@@@@@" << std::endl;
	// Note: check() has 3 CondLikelihood & args, but we only need 2 of them, so first 2 are same and 3rd represents child's cond. like
	underflow_manager.check(condLike, condLike, childCondLike, pattern_counts, true);	// last argument is polytomy
#endif
	}

//move this to member fxn of Tree
// static int nodeIndex(TreeNode *p)
// 	{
// 	return (p == NULL) ? -1 : p->GetNodeNumber();
// 	}

/*----------------------------------------------------------------------------------------------------------------------
|	Called after neighboring conditional likelihood arrays are brought up-to-date. The focal_neighbor of focal_edge is
|   NULL if this function is called from TreeLikelihood::calcLnLFromNode (which is the usual situation).
*/
double TreeLikelihood::harvestLnL(
   EdgeEndpoints & focal_edge,	/**< is a pair of TreeNode pointers, the first of which points to the likelihood root node and the second is usually NULL */
   TreeShPtr t)					/**< is the tree */
	{
#if 0//old
	// Get the focal node
	TreeNode * focal_node = focal_edge.getFocalNode();
	PHYCAS_ASSERT(focal_node != NULL);

printf("in harvestLnL with EdgeEndpoints=(%d,%d)\n", nodeIndex(focal_edge.getFocalNode()), nodeIndex(focal_edge.getFocalNeighbor()));//

	// If the focal neighbor is NULL (the usual case), let the parent of the focal node be the focal neighbor
	TreeNode * focal_neighbor = focal_edge.getFocalNeighbor();
	if (focal_neighbor == NULL)
		{
		focal_neighbor = focal_node->GetParent();
		focal_edge.setFocalNeighbor(focal_neighbor);
		}
	PHYCAS_ASSERT(focal_neighbor != NULL);

	// Recompute the conditional likelihood array of the focal node
	refreshCLA(*focal_node, focal_neighbor);
	ConstEdgeEndpoints c(focal_node, focal_neighbor);
	return harvestLnLFromValidEdge(c);
#else
	double lnL;

	// Get the focal node
	TreeNode * focal_node = focal_edge.getFocalNode();
	PHYCAS_ASSERT(focal_node != NULL);

//printf("in harvestLnL with EdgeEndpoints=(%d,%d)\n", nodeIndex(focal_edge.getFocalNode()), nodeIndex(focal_edge.getFocalNeighbor()));//

	TreeNode * focal_neighbor = focal_edge.getFocalNeighbor();
	if (focal_neighbor == NULL)
		{
		focal_neighbor = focal_node->GetParent();
		focal_edge.setFocalNeighbor(focal_neighbor);
		}
	PHYCAS_ASSERT(focal_neighbor != NULL);

	// Recompute the conditional likelihood array of the focal node
//printf("calling refreshCLA\n");//
	refreshCLA(*focal_node, focal_neighbor);
//printf("back from refreshCLA\n");//

//printf("getting ready\n");//
	PHYCAS_ASSERT(t);
	if (t->IsRooted())
		{
//printf("calling rooted version\n");
		lnL = harvestLnLFromValidNode(focal_node);
		}
	else
		{
		// If the focal neighbor is NULL (the usual case), let the parent of the focal node be the focal neighbor
//printf("calling unrooted version\n");
		ConstEdgeEndpoints c(focal_node, focal_neighbor);
		lnL = harvestLnLFromValidEdge(c);
		}

//printf("returning lnL=%g\n", lnL);//
	return lnL;

#endif
	}

/*----------------------------------------------------------------------------------------------------------------------
|	Calculates log-likelihood using the focal node of `focal_edge' as the likelihood root. Assumes that all the
|	necessary conditional likelihood arrays that are needed are up-to-date.
|
|	Conditional likelihood arrays are laid out as follows for DNA data:
|>
|	+-----------------------------------------------------+-----------------------------------------------------+
|	|                        rate 1                       |                        rate 2                       | ...
|	+-----------------------------------------------------+-----------------------------------------------------+
|	|   pattern 1   |   pattern 2   | ... |   pattern n   |   pattern 1   |   pattern 2   | ... |   pattern n   | ...
|	+-----------------------------------------------------+-----------------------------------------------------+
|	| A | C | G | T | A | C | G | T | ... | A | C | G | T | A | C | G | T | A | C | G | T | ... | A | C | G | T | ...
|	+-----------------------------------------------------+-----------------------------------------------------+
|>
|	For partitioned data (first subset with 2 rates and 3 binary patterns, second subset with 1 rate and 2 DNA
|	patterns):
|>
|	+-----------------------+-----------------------+-------------------------------+
|	|                    subset 1                   |           subset 2            |
|	+-----------------------+-----------------------+-------------------------------+
|	|           r1          |           r2          |               r1              |
|	+-----------------------+-----------------------+-------------------------------+
|	|  p1   |  p2   |  p3   |  p1   |  p2   |  p3   |      p1       |       p2      |
|	+-----------------------+-----------------------+-------------------------------+
|	| 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | A | C | G | T | A | C | G | T |
|	+-----------------------+-----------------------+-------------------------------+
|>
*/
double TreeLikelihood::harvestLnLFromValidEdge(
   ConstEdgeEndpoints & focal_edge)	/**< is the edge containing the focal node that will serve as the likelihood root */
    {
	//debugCompressedDataInfo("compressed_data_info.txt");

    // Create convenience variables focalNode, focalNeighbor, actualChild, focalEdgeLen, focalCondLike, focalNodeCLA,
    // and singleRateCLALength
    PHYCAS_ASSERT(focal_edge.getFocalNode() != NULL);
    PHYCAS_ASSERT(focal_edge.getFocalNeighbor() != NULL);
    const TreeNode * 			focalNeighbor		= focal_edge.getFocalNeighbor();
    const TreeNode * 			focalNode			= focal_edge.getFocalNode();
    PHYCAS_ASSERT(focalNode->IsInternal());
    const TreeNode * 			actualChild			= focal_edge.getActualChild();
    const double 				focalEdgeLen 		= actualChild->GetEdgeLen();
    ConstCondLikelihoodShPtr 	focalCondLike 		= getValidCondLikePtr(focal_edge);
    PHYCAS_ASSERT(focalCondLike);
    const LikeFltType * 		focalNodeCLA 		= focalCondLike->getCLA(); //PELIGROSO
    PHYCAS_ASSERT(focalNodeCLA != NULL);

    // Get pointer to start of array holding pattern counts
	PHYCAS_ASSERT((unsigned)pattern_counts.size() == std::accumulate(partition_model->subset_num_patterns.begin(), partition_model->subset_num_patterns.end(), (unsigned)0));
    const pattern_count_t * const counts = (const pattern_count_t * const)(&pattern_counts[0]); //PELIGROSO

    // Get pointer to start of array holding number of potentially constant states for each pattern
    // A potentially constant state for a pattern is a state present in all taxa with unambiguous data.
    // If there are ambiguities, then it is possible that the pattern is not constant depending on
    // the way these ambiguities are resolved. Here is what this vector looks like:
	// +---+---+---+---+---+---+---+---+
	// | 0 | 1 | 0 | 1 | 3 | 2 | 0 | 2 |
	// +---+---+---+---+---+---+---+---+
	//   ^   ^       ^       ^
	//   |   |       |       |
	//   |   |       |       4th site can potentially be constant for either A (state 0) or G (state 2)
	//   |   |       3rd site can be potentially constant for T (state 3)
	//   |   2nd site can be potentially constant for 1 state: that state (A, state 0) follows in the next cell
	//   1st site is definitely variable (hence the 0 meaning no states follow)
    const unsigned * pinvar_states = &constant_states[0]; //PELIGROSO

    unsigned pattern_start = 0;
	unsigned cum_cla_pos = 0;

    if (store_site_likes)
        {
        site_likelihood.clear();
        site_uf.clear();
        }

    double lnLikelihood = 0.0;
    unsigned num_subsets = partition_model->getNumSubsets();
    for (unsigned i = 0; i < num_subsets; ++i)
        {
        // Make local variables for compiler optimization
        unsigned		ns					= partition_model->subset_num_states[i];
        unsigned		nr					= partition_model->subset_num_rates[i];
        unsigned		np					= partition_model->subset_num_patterns[i];
        const unsigned	singleRateCLALength	= np*ns;

        // Get state frequencies from model and alias rate category probability array for speed
        const double *	stateFreq			= &partition_model->subset_model[i]->getStateFreqs()[0]; //PELIGROSO

        //const double * 	rateCatProbArray	= &rate_probs[i][rate_prob_start]; //PELIGROSO
        const double * 	rateCatProbArray	= &rate_probs[i][0]; //PELIGROSO

        bool			is_pinvar			= partition_model->subset_model[i]->isPinvarModel();
        double			pinvar				= partition_model->subset_model[i]->getPinvar();

        if (focalNeighbor->IsTip())
            {
            const TipData &					tipData 			= *focalNeighbor->GetTipData();
            double * * *					p					= tipData.getMutableTransposedPMatrices(i);
            const double * const * const *	tipPMatricesTrans	= tipData.getConstTransposedPMatrices(i);
            const int8_t *					tipStateCodes		= tipData.getConstStateCodes(i);
            std::vector<const double *> 	focalNdCLAPtr(nr);

            // Compute transition probability matrices (one for each relative rate) for the edge
            // connecting the tip node to the focal node
            calcPMatTranspose(i, p, tipData.getConstStateListPos(i),  focalEdgeLen);

            // Set focalNdCLAPtr so that element r points to the CLA of the first state of the
            // starting pattern for relative rate r
            for (unsigned r = 0; r < nr; ++r)
            	focalNdCLAPtr[r] = focalNodeCLA + cum_cla_pos + singleRateCLALength*r;

            for (unsigned pat = pattern_start; pat < pattern_start + np; ++pat)
                {
				// get index of pattern relative to first pattern in current partition subset
				unsigned relpat = pat - subset_offset[i];

                // Compute the site likelihood for the current pattern
                double siteLike = 0.0;
                for (unsigned r = 0; r < nr; ++r)
                    {
                    const double * const * const	tipPMatrixT		= tipPMatricesTrans[r];
					int8_t							from_state		= tipStateCodes[relpat];
                    const double *					tipPMatT_pat	= tipPMatrixT[from_state];
                    double 							siteRateLike 	= 0.0;

                    // Go through possible states at the internal (focal) node
                    for (unsigned s = 0; s < ns; ++s)
                        {
                        double frq 		= stateFreq[s];			// frequency of state s
                        double clike 	= focalNdCLAPtr[r][s];	// likelihood conditional of state s at focal node
                        double tprob	= tipPMatT_pat[s];		// trans. prob. of tip state to state s
                        siteRateLike += frq*clike*tprob;		//@POL does this assume time-reversible model (using tipPMatT_pat backwards)?
                        }
					double rate_cat_prob = rateCatProbArray[r];
                    siteLike += siteRateLike*rate_cat_prob;

					//std::cerr << boost::str(boost::format("i = %d, r = %d, siteRateLike = %.8f") % i % r % siteRateLike) << std::endl;

                    // Increment starting positions to next pattern for this relative rate
                    focalNdCLAPtr[r] += ns;
                    }

                double log_correction_factor = underflow_manager.getCorrectionFactor(pat, focalCondLike);

                if (is_pinvar)
                    {
                    double pinvar_like = 0.0;
                    unsigned num_pinvar_states = *pinvar_states++;
                    if (num_pinvar_states > 0)
                        {
                        // This pattern is at least potentially constant, so we must compute pinvar_like,
                        // the likelihood conditional on the site having rate = 0
                        for (unsigned s = 0; s < num_pinvar_states; ++s)
                            pinvar_like += stateFreq[*pinvar_states++];

                        if (log_correction_factor != 0.0)
                            {
                            // If variable part of site-likelihood has been corrected for underflow,
                            // we must also correct the invariable component

                            // find correction factor (f) for pinvar_like
                            double underflow_max_value = underflow_manager.getUnderflowMaxValue();
                            PHYCAS_ASSERT(pinvar_like > underflow_max_value/DBL_MAX);
                            double ratio = underflow_max_value/pinvar_like;
                            double log_ratio = std::log(ratio);
                            double f = std::floor(log_ratio);

                            if (f < log_correction_factor)
                                {
                                double expdiff = exp(f - log_correction_factor);
                                pinvar_like *= exp(f);
                                siteLike *= expdiff;
                                log_correction_factor = f;
                                }
                            else
                                {
                                // since log_correction_factor <= f, and since exp(f) is in no danger of overflowing,
                                // we need not worry about exp(log_correction_factor) overflowing
                                double expc = exp(log_correction_factor);
                                pinvar_like *= expc;
                                }
                            }
                        siteLike = pinvar*pinvar_like + (1.0 - pinvar)*siteLike;
                        }
                    else
                        {
                        // This pattern is not constant (or even potentially constant), so the probability
                        // of the data given invariability is zero
                        siteLike = (1.0 - pinvar)*siteLike;
                        }
                    }

                double site_lnL = std::log(siteLike);
                site_lnL -= log_correction_factor;

				//std::cerr << boost::str(boost::format("--> i = %d, siteLike = %.8f, site_lnL = %.8f") % i % siteLike % site_lnL) << std::endl;

                if (store_site_likes)
                    {
                    site_likelihood.push_back(site_lnL);
                    site_uf.push_back(log_correction_factor);
                    }
                lnLikelihood += counts[pat]*site_lnL;
                } // pat loop
            }
        else    // focalNeighbor is not a tip
            {
			ConstCondLikelihoodShPtr	neighborCondLike	= getValidCondLikePtr(focalNeighbor, focalNode);
			PHYCAS_ASSERT(neighborCondLike);
			const double *				focalNeighborCLA	= neighborCondLike->getCLA(); //PELIGROSO
			PHYCAS_ASSERT(focalNeighborCLA != NULL);
            const InternalData *			neighborID		= focalNeighbor->GetInternalData();
            const double * const * const *	childPMatrices	= neighborID->getConstPMatrices(i);

            // Compute transition probability matrices (one for each relative rate) for the edge
            // connecting the two internal nodes
            calcPMat(i, neighborID->getMutablePMatrices(i), focalEdgeLen);

    		// Create vectors whose elements point to the starting state CLA for each rate
    		// Each element is updated after each pattern to point ns ahead to the next pattern.
			//
			// +-----------------------------------------------------------------------------------------------+-------------------------------+
			// |                                            subset 1                                           |           subset 2            |
			// +-----------------------------------------------------------------------------------------------+-------------------------------+
			// |                      r1                       |                      r2                       |               r1              |
			// +-----------------------------------------------+-----------------------------------------------+-------------------------------+
			// |      p1       |      p2       |       p3      |      p1       |      p2       |      p3       |      p1       |       p2      |
			// +-----------------------------------------------+-----------------------------------------------+-------------------------------+
			// | A | C | G | T | A | C | G | T | A | C | G | T | A | C | G | T | A | C | G | T | A | C | G | T | A | C | G | T | A | C | G | T |
			// +-----------------------------------------------+-----------------------------------------------+-------------------------------+
            std::vector<const double *> focalNdCLAPtr(nr);
            std::vector<const double *> focalNeighborCLAPtr(nr);

    		// Create an expected divergence matrix piP that is equivalent to a diagonal matrix of
    		// state frequencies multiplied by the transition probability matrix. This represents
    		// a precalculation that will save time later on.
            ScopedThreeDMatrix<double> piP;
            piP.Initialize(nr, ns, ns);

			// Set focalNdCLAPtr and focalNeighborCLAPtr so that element r points to the CLA of
			// the first state of the starting pattern for relative rate r. Also compute elements
			// of piP matrix.
            for (unsigned r = 0; r < nr; ++r)
                {
				//std::cerr << "childPMatrices[" << r << "]" << std::endl;
                focalNdCLAPtr[r]		= focalNodeCLA		+ singleRateCLALength*r	+ cum_cla_pos;	// bug fixed in svn revision 1209: cum_cla_pos was ns*pattern_start, which
                focalNeighborCLAPtr[r]	= focalNeighborCLA	+ singleRateCLALength*r	+ cum_cla_pos;	// doesn't work because ns might differ across subsets
                for (unsigned neighbor_state = 0; neighbor_state < ns; ++neighbor_state)
                    {
					//std::cerr << boost::str(boost::format("> stateFreq[%d] = %.8f") % neighbor_state % stateFreq[neighbor_state]) << std::endl;
                    for (unsigned focal_state = 0; focal_state < ns; ++focal_state)
                        {
                        piP.ptr[r][neighbor_state][focal_state] = stateFreq[neighbor_state]*childPMatrices[r][neighbor_state][focal_state];
						//std::cerr << boost::str(boost::format("  focal_state = %d, neighbor_state = %.8f, childPMatrices[r][neighbor_state][focal_state] = %.8f") % focal_state % neighbor_state % childPMatrices[r][neighbor_state][focal_state]) << std::endl;
                        }
                    }
                }

            for (unsigned pat = pattern_start; pat < pattern_start + np; ++pat)
                {
                double siteLike = 0.0;
                for (unsigned r = 0; r < nr; ++r)
                    {
                    const double *	focalNdCLAPtr_r 	= focalNdCLAPtr[r];
                    const double *	neighborCLAForRate 	= focalNeighborCLAPtr[r];
                    double 			siteRateLike		= 0.0;

                    // sum_f Lf (sum_n pi_n P_{n,f} Ln) --> f = focal state, n = neighbor state, Lf = cla focal node, Ln = cla neighbor node
                    // sum_f Lf (sum_n   piPnf      Ln) --> piPnf = pi_n P_{n,f}
                    // sum_f Lf (     neigborLike     ) --> neighborLike = sum_n piPnf Ln
                    for (unsigned focal_state = 0; focal_state < ns; ++focal_state)
                        {
                        double Lf = focalNdCLAPtr_r[focal_state];

                        double neigborLike = 0.0;
                        const double * piP_focal_state = piP.ptr[r][focal_state];	// get pointer to row of piP matrix corresponding to focal_state
                        for (unsigned neighbor_state = 0; neighbor_state < ns; ++neighbor_state)
                        	{
                        	double Ln 		= neighborCLAForRate[neighbor_state];
                        	double piPnf 	= piP_focal_state[neighbor_state];	//@POL this assumes time-reversible model (using piP backwards)
                            neigborLike += piPnf*Ln;
							//std::cerr << boost::str(boost::format("  focal_state = %d, neighbor_state = %.8f, Lf = %.8f, Ln = %.8f, piPnf = %.8f, neigborLike(cum) = %.8f") % focal_state % neighbor_state % Lf % Ln % piPnf % neigborLike) << std::endl;
                            }

						//std::cerr << boost::str(boost::format("i = %d, r = %d, focal_state = %d, neighborLike = %.8f, Lf = %.8f, siteRateLike = %.8f") % i % r % focal_state % neigborLike % Lf % (Lf*neigborLike)) << std::endl;

                        siteRateLike += Lf*neigborLike;
                        }
                    siteLike += siteRateLike*rateCatProbArray[r];

					// Increment starting positions to next pattern for this relative rate
                    focalNdCLAPtr[r] 		+= ns;
                    focalNeighborCLAPtr[r]	+= ns;
                    }

                double log_correction_factor = underflow_manager.getCorrectionFactor(pat, focalCondLike);
                log_correction_factor 		+= underflow_manager.getCorrectionFactor(pat, neighborCondLike);

                if (is_pinvar)
                    {
                    double pinvar_like = 0.0;
                    unsigned num_pinvar_states = *pinvar_states++;
                    if (num_pinvar_states > 0)
                        {
                        // This pattern is at least potentially constant, so we must compute pinvar_like,
                        // the likelihood conditional on the site having rate = 0
                        for (unsigned j = 0; j < num_pinvar_states; ++j)
                            pinvar_like += stateFreq[*pinvar_states++];

                        if (log_correction_factor != 0.0)
                            {
                            // If variable part of site-likelihood has been corrected for underflow,
                            // we must also correct the invariable component

                            // find correction factor (f) for pinvar_like
                            double underflow_max_value = underflow_manager.getUnderflowMaxValue();
                            PHYCAS_ASSERT(pinvar_like > underflow_max_value/DBL_MAX);
                            double ratio = underflow_max_value/pinvar_like;
                            double log_ratio = std::log(ratio);
                            double f = std::floor(log_ratio);

                            if (f < log_correction_factor)
                                {
                                double expdiff = exp(f - log_correction_factor);
                                pinvar_like *= exp(f);
                                siteLike *= expdiff;
                                log_correction_factor = f;
                                }
                            else
                                {
                                // since log_correction_factor <= f, and since exp(f) is in no danger of overflowing,
                                // we need not worry about exp(log_correction_factor) overflowing
                                double expc = exp(log_correction_factor);
                                pinvar_like *= expc;
                                }
                            }
                        siteLike = pinvar*pinvar_like + (1.0 - pinvar)*siteLike;
                        }
                    else
                        {
                        // This pattern is not constant (or even potentially constant), so the probability
                        // of the data given invariability is zero
                        siteLike = (1.0 - pinvar)*siteLike;
                        }
                    }

                double site_lnL = std::log(siteLike);
                site_lnL -= log_correction_factor;

				//std::cerr << boost::str(boost::format("--> i = %d, siteLike = %.8f, site_lnL = %.8f") % i % siteLike % site_lnL) << std::endl;

                if (store_site_likes)
                    {
                    site_likelihood.push_back(site_lnL);
                    site_uf.push_back(log_correction_factor);
                    }

                lnLikelihood += counts[pat]*site_lnL;
                }
            }
            pattern_start += np;
			cum_cla_pos += nr*np*ns;
        }   // loop over subsets of partition

        return lnLikelihood;
    }

double TreeLikelihood::harvestLnLFromValidNode(
   TreeNode * focalNode)	/**< a node whose conditional likelihoods are now valid and ready for final likelihood calculation */
	{
    // Create convenience variables focalNode, focalNeighbor, actualChild, focalEdgeLen, focalCondLike, focalNodeCLA,
    // and singleRateCLALength
    PHYCAS_ASSERT(focalNode->IsInternal());
    InternalData * id = focalNode->GetInternalData();
    ConstCondLikelihoodShPtr focalCondLike = id->getValidChildCondLikePtr();
    PHYCAS_ASSERT(focalCondLike);
    const LikeFltType * focalNodeCLA = focalCondLike->getCLA(); //PELIGROSO
    PHYCAS_ASSERT(focalNodeCLA != NULL);

    // Get pointer to start of array holding pattern counts
	PHYCAS_ASSERT((unsigned)pattern_counts.size() == std::accumulate(partition_model->subset_num_patterns.begin(), partition_model->subset_num_patterns.end(), (unsigned)0));
    const pattern_count_t * const counts = (const pattern_count_t * const)(&pattern_counts[0]); //PELIGROSO

	// Get pointer to start of array holding number of potentially constant states for each pattern
	// A potentially constant state for a pattern is a state present in all taxa with unambiguous data.
	// If there are ambiguities, then it is possible that the pattern is not constant depending on
	// the way these ambiguities are resolved. Here is what this vector looks like:
	// +---+---+---+---+---+---+---+---+
	// | 0 | 1 | 0 | 1 | 3 | 2 | 0 | 2 |
	// +---+---+---+---+---+---+---+---+
	//   ^   ^       ^       ^
	//   |   |       |       |
	//   |   |       |       4th site can potentially be constant for either A (state 0) or G (state 2)
	//   |   |       3rd site can be potentially constant for T (state 3)
	//   |   2nd site can be potentially constant for 1 state: that state (A, state 0) follows in the next cell
	//   1st site is definitely variable (hence the 0 meaning no states follow)
	const unsigned * pinvar_states = &constant_states[0]; //PELIGROSO

	// The following explanation is not correct - now separate vectors for each subset
	// The rate_probs vector holds rate probs for all subsets. For example, here is what it would look like
	// if the first of 3 subsets had 4 rate categories, the second subset had 1 rate category (i.e.
	// rate homogeneity model), and the third subset had 2 rate categories:
	//	+------+------+------+------+----------+------+------+
	//	|          subset 1         | subset 2 |   subset 3  |
	//	+------+------+------+------+----------+------+------+
	//	| 0.25 | 0.25 | 0.25 | 0.25 |   1.00   | 0.50 | 0.50 |
	//	+------+------+------+------+----------+------+------+
	// The rate_prob_start variable holds the index of the first element in this vector for the current
	// subset; for the example above, it would start at 0 for the first subset, then change to 4 for the
	// second subset, and end at 5 for the third and final subset.
	//unsigned rate_prob_start = 0;
	unsigned pattern_start = 0;

	if (store_site_likes)
        {
        site_likelihood.clear();
        site_uf.clear();
        }

    double lnLikelihood = 0.0;

	unsigned num_subsets = partition_model->getNumSubsets();
	for (unsigned i = 0; i < num_subsets; ++i)
		{
		// Make local variables for compiler optimization
		unsigned		ns					= partition_model->subset_num_states[i];
		unsigned		nr					= partition_model->subset_num_rates[i];
		unsigned		np					= partition_model->subset_num_patterns[i];

		//temp!
		//double ssrr = partition_model->getSubsetRelRate(i);
		//std::cerr << "Subset relative rate for subset " << i << " is " << ssrr << std::endl;

		const unsigned	singleRateCLALength	= np*ns;

		// Get state frequencies from model and alias rate category probability array for speed
		const double *	stateFreq			= &partition_model->subset_model[i]->getStateFreqs()[0]; //PELIGROSO

		//const double * 	rateCatProbArray	= &rate_probs[i][rate_prob_start]; //PELIGROSO
		const double * 	rateCatProbArray	= &rate_probs[i][0]; //PELIGROSO

		bool			is_pinvar			= partition_model->subset_model[i]->isPinvarModel();
		double			pinvar				= partition_model->subset_model[i]->getPinvar();

		std::vector<const double *> focalNdCLAPtr(nr);
		for (unsigned r = 0; r < nr; ++r)
			focalNdCLAPtr[r] = focalNodeCLA + singleRateCLALength*r;

		for (unsigned pat = 0; pat < np; ++pat)
			{
			double siteLike = 0.0;
			for (unsigned r = 0; r < nr; ++r)
				{
				const double * focalNdCLAPtr_r = focalNdCLAPtr[r];
				double siteLike_r = 0.0;
				for (unsigned i = 0; i < ns; ++i)
                    {
					siteLike_r += focalNdCLAPtr_r[i]*stateFreq[i];

                    //@POLTEMP
                    //std::cerr << boost::str(boost::format("pat=%d, rate=%d, state=%d, cla=%g, freq=%g, like=%g") % pat % r % i % focalNdCLAPtr_r[i] % stateFreq[i] % siteLike_r) << std::endl;
                    }
				siteLike += rateCatProbArray[r]*siteLike_r;
				focalNdCLAPtr[r] += ns;
				}

			double log_correction_factor = underflow_manager.getCorrectionFactor(pat, focalCondLike);

			if (is_pinvar)
				{
				double pinvar_like = 0.0;
				unsigned num_pinvar_states = *pinvar_states++;
				if (num_pinvar_states > 0)
					{
					//DLS: this can all be precalculated in one trip through the patterns, just adding a single value to the likelihoods not conditioned on the site being constant
					for (unsigned i = 0; i < num_pinvar_states; ++i)
						pinvar_like += stateFreq[*pinvar_states++];

					if (log_correction_factor != 0.0)
						{
						// If variable part of site-likelihood has been corrected for underflow,
						// we must also correct the invariable component

						// find correction factor (f) for pinvar_like
						double underflow_max_value = underflow_manager.getUnderflowMaxValue();
						PHYCAS_ASSERT(pinvar_like > underflow_max_value/DBL_MAX);
						double ratio = underflow_max_value/pinvar_like;
						double log_ratio = std::log(ratio);
						double f = std::floor(log_ratio);

						if (f < log_correction_factor)
							{
							double expdiff = exp(f - log_correction_factor);
							pinvar_like *= exp(f);
							siteLike *= expdiff;
							log_correction_factor = f;
							}
						else
							{
							// since log_correction_factor <= f, and since exp(f) is in no danger of overflowing,
							// we need not worry about exp(log_correction_factor) overflowing
							double expc = exp(log_correction_factor);
							pinvar_like *= expc;
							}
						}
					siteLike = pinvar*pinvar_like + (1.0 - pinvar)*siteLike;
					}
				else
					{
					// This pattern is not constant (or even potentially constant), so the probability
					// of the data given invariability is zero
					siteLike = (1.0 - pinvar)*siteLike;
					}
			}

			double site_lnL = std::log(siteLike);
			site_lnL -= log_correction_factor;

			if (store_site_likes)
				{
				site_likelihood.push_back(site_lnL);
				site_uf.push_back(log_correction_factor);
				}

			lnLikelihood += counts[pat]*site_lnL;
			}   // loop over patterns

		//rate_prob_start += nr;
		pattern_start += np;
		}	// loop over subsets of partition

        return lnLikelihood;
    }

} //namespace phycas
